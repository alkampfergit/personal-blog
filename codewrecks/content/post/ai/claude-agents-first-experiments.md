---
title: "First experiments with Claude Code - Writing specs"
description: "I always use LLM to help write detailed specs for sofware I want to create especially if I'm trying to use vibe coding. Claude Code seems promising in creating agents to help you in this process automating the whole process"
date: 2025-08-02T06:00:00+00:00
draft: false
tags: ["Claude", "AI", "Vibe Coding"]
categories: ["AI"]
---

If you want to use vibe coding, it is highly advisable that you create detailed specification for the result you want. This happens because the more freedom you're left to the model, the more the result can be different from what you need.

In this scenario, the easiest way to accomplish this task is using a model to help you writing detailed specification. So you can quickly have a really good and detailed specs that you can simply manual refining for your need. Usually I do this with various model and using Open web UI.

Now that Cloud Code bring agents to the public and creating an agent is really simple, I've immediately tried to create a series of agents that help me to follow this process automatically. The result is good, but not so good. The main problem is that Cloud Code seems to be focused in writing code and seems to be really proactive to give more than you really need. So if you start with a simple idea and ask to Claude Code to create an agent for brainstorming an idea to create detailed specification, the result is good. But how really good is the result?

The problem is that you should check everything that gets output by a large language model, because it can hallucinate and it can be different from what you really need. So if I start with an idea and it generates a very high number of file with very detailed specification, I will need a lot of time to review what the large language model generates. And that is important because I really want to understand how to bring my idea to life in vibe coding but I don't want to generate an overcomplicated thing. So the problem is you can ask that you want to generate a simple application for interacting with large language model by commandline and you will end with a monster that does too much.

After all, the Pareto rule always applies, So probably I will end with a code where the 20% is what I asked and what I need, and the 80% is something generated by the large language model that believes that you really need those code. My suggestion to avoid this problem is I start with a simple model and I clearly instruct that I want him to generate only a list of bullet points of the macro feature I need to accomplish my idea. Usually the first round generate too much bullet points and then I simply edit the answer of the large language model and I remove all the points that do not want and I add that one I think that are missing. I continue in edit the answer of the large language model and ask for a refinement thanks to the ability of Open Web UI to edit every part of the conversation. In the end, I quickly have a list of ballot points that contains only the thing I want to be implemented.

Then you take each one of the points and ask to the large language model, maybe a smarter model to elaborate and create a list of really user story practical tasks that need to be implemented and I go on and on and on until I have a complete list of what I need.

> The secret for having a good result is reading everything that the large language model generates and refining it to fit your needs.

So I always pro ceed in interaction and each interaction I ask the larger queue model not to generate too much stuff so I can keep everything in control. I can keep everything in scope and in the end I have a list of specification that usually contains only the thing I want to be implemented in Vibe coding.

Now I'm trying to replicate this with Claude Agents, So I start creating an agent that should only write down a list of bullet point with specification. Something that is simple. What I found is probably Cloud Code has some sort of context, prompt or instruction that clearly bring the model to do more than The thing you ask it to do;

![Claude helping me in drawing specifications.](../images/claude-first-interaction.png)

***Figure 1:*** *Claude helping me in drawing specifications*

We can see that I've create the agent (1), then ask to brainstorm (2) then it is activated (3) and it starts generating me stuff (4). I can drive him to what I need such as using simple file storage (5) and the result seems to be really really good (6). The problem is that it is not so good as I expected, because it generates too much stuff and I need to refine it. 

If you look at the picture, you'll see that it also generates some sort of graphic in text format that helps me to understand how the solution is structured.

If you look at the agent that was generated by Claude Code (yes it asks you a brief description and the it generates agents specification for you), it is really, really complex. So I try to edit and put only the instruction I need in the agent, hoping that having an agent simpler I will have a simpler solution.

![My refined brainstormer that contains less instruction and is really specific.](../images/claude-refined-agent.png)

***Figure 2:*** *My refined brainstormer that contains less instruction and is really specific*

The focus of this new agent is telling. Specifically that I really want only a couple of files and one of the file is a specification file that should contains only a very brief list of specifications: one line for each feature I want. 

This is because when I want to create a software with Vibe Coding, I want to immediately look at the set of macroscopic featurea I want. I clearly specify that the focus of this agent is modifying two 5, and I explicitly specify that after each interaction I wanted to modify this file so I can immediately look at the results. This way of working is what I want because I can look at the simple file I can quickly modify and tell the model, hey, I modified your first proposal. Now let's refine a little bit.

And the agents still not follows my instructions. First of all, quite often after the first proposal it asked me if it should start to implement it. But that explicitly not what I want. I just want to create a simple list. Sometimes the result is too detailed. It not only lists the feature but also create a long detailed instruction for the start to be used and it write too many stuff for each features.

And what I find most disturbing, it is not writing the files.

![Claude agent seems to somewhat ignoring my instructions.](../images/claude-not-following-instructions.png)

***Figure 3:*** *Claude agent seems to somewhat ignoring my instructions*

As you can see it did not create the file. I asked him to create the file and it correctly. Tell me that debris storming agent mentioned creating specs.md and project structure. Ok at least after explicitly instruction it seems to be right on track. But look at the last line of the picture. The name of the file is not the name I specified into the instructions. So even if it answers me that it correctly contains instruction to write specs.md files, He is writing a different file name. 

Now I tell him to do things differently answering: **Yor instructions specify that the file should be called specs.md**

He created two file, the specs.md and the project-structure.md, a file that was never mentioned in the instructions, but i told him that one of the result I want is the project structure so it could be good to have it.

But I have now 214 lines of project structure that I need to review... too detailed.

![Clearly this is too detailed, it contains API description.](../images/claude-overspecification.png)

***Figure 4:*** *Clearly this is too detailed, it contains API description.*

Wow, it contains API descriptions, clearly I do not need them at this level. Then in the following picture I show what Claude tell me in the prompt.

![Content of the console where Claude Code is running.](../images/claude-prompt-content.png)

***Figure 4:*** *Content of the console where Claude Code is running.*

From the previous picture you'll see that the result is quite good. Actually he is creating a simple list of features. But when I tell him to save and I open the file, the result file has 100 lines. That is another big problem. What it is telling me in the console prompt in the interaction with the model is not what is writing into the file.

This is using haiku model, and sadly enough the interaction with Claude Code seems to be slow. This suggests me that even with this simple assistant Claude is using its secret sauce to be more proactive and generate more than what I need.

Now compare with what I usually do with Openwebui. I've copied the exact same prompt I've used for the Claude Agent in and uses Haiku model. I've asked the same question and the model instantaneously. Answer me, please give me some more detail. I told the model that I want a software that helps me to refine user stories thanks to a large language model. After no more than three seconds I got the result in the below picture.

![Results of haiku used directly with API and OpenWebUi](../images/haiku-results.png)
***Figure 4:*** *Results of haiku used directly with API and OpenWebUi.*

The result need to be refined, but as you can see it's almost instantaneously to have an answer. And the answer is exactly what I need. A simple ballot point list of microscopic feature and a cloud markdown file that contains technical specification.

This suggests me that clothed COD, even if you specify a specific prompt for an agent, always use some internal structure to make the agent more intelligent, more smart, but sometimes is absolutely not what you need.

Nevertheless, it is a giant leap forward because it is really good in writing code. So I'm still sticking to direct API Calls to create specification and then use Claude code to do the vibe coding.

Gian Maria